{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To embed plots in the notebooks\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np # numpy library\n",
    "import scipy . linalg as lng # linear algebra from scipy library\n",
    "from scipy . spatial import distance # load distance function\n",
    "from sklearn import preprocessing as preproc # load preprocessing function\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# seaborn can be used to \"prettify\" default matplotlib plots by importing and setting as default\n",
    "import seaborn as sns\n",
    "sns.set() # Set searborn as default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetPath = './DiabetesDataNormalized.txt'\n",
    "T = np.loadtxt(diabetPath, delimiter = ' ', skiprows = 1)\n",
    "y = T[:, 10]\n",
    "X = T[:,:10]\n",
    "\n",
    "# Get number of observations (n) and number of independent variables (p)\n",
    "[n, p] = np.shape(X)\n",
    "\n",
    "M = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Solve the Ordinary Least Squares (OLS) computationally (for the diabetes data set):\n",
    "\n",
    "> (a) What is the difference between using a brute force implementation fo an OLS solver and a numerically ’smarter’ implementation? Compute the ordinary least squares solution to the diabetes data set for both options and look at the relative difference. Use for example lng.lstsq to invert the matrix or to solve the linear system of equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(X, y, b):\n",
    "    cross = X.dot(b)\n",
    "    error = sum((y - cross)**2)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_solver(X, y):\n",
    "    stable = np.zeros(X.shape[1])\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    learning_rate = 0.001\n",
    "    error_last = 0\n",
    "    error_curr = 0\n",
    "    n_prog = 0\n",
    "    while (stable == np.full(X.shape[1],0)).any():\n",
    "        for n,variable in enumerate(beta):\n",
    "            beta_dict = {'u':np.copy(beta),'l':np.copy(beta),'c':np.copy(beta)}\n",
    "            error_dict = {'u':0,'l':0,'c':0}\n",
    "            beta_dict['u'][n] += learning_rate\n",
    "            beta_dict['l'][n] -= learning_rate\n",
    "            error_dict['u'] = calculate_error(X, y, beta_dict['u'])\n",
    "            error_dict['l'] = calculate_error(X, y, beta_dict['l'])\n",
    "            error_dict['c'] = calculate_error(X, y, beta_dict['c'])\n",
    "            opt_ind = min({x:error_dict[x] for x in error_dict}, key=error_dict.get)\n",
    "            beta[n] = beta_dict[opt_ind][n]\n",
    "            if opt_ind == 'c':\n",
    "                stable[n] = 1\n",
    "            else:\n",
    "                stable[n] = 0\n",
    "            error_last = error_curr\n",
    "            error_curr = error_dict[opt_ind]\n",
    "            \n",
    "            if error_curr < error_last - 0.000001:\n",
    "                n_prog = 0\n",
    "            else:\n",
    "                n_prog += 1\n",
    "        if n_prog > 100:\n",
    "            learning_rate = (learning_rate-1)/2 + 1\n",
    "        if learning_rate < 0.00000001:\n",
    "            print('lr')\n",
    "            break\n",
    "    \n",
    "    return beta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ols_numerical(X, y):\n",
    "    # Implement the numerical way of calculating the betas \n",
    "    return np.linalg.inv((X.T.dot(X))).dot(X.T).dot(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the two methods you just created to calculate the betas and inspect the relative difference\n",
    "beta_bad = ols_solver(X,y)\n",
    "beta_good = ols_numerical(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (b) How could you include an intercept term in Python? This means using the model: $y = β_0 +xβ_1 +...+x_pβ_p +ε $ rather than: $ y=x_1β_1 +...+x_pβ_p +ε. $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [1, 2, 3, 1],\n",
       "       [1, 2, 3, 1]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [[1,2,3],[1,2,3]]\n",
    "np.pad(tmp,((1,0),(0,1)),mode='constant',constant_values=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.18292545e-03 -1.48130075e-01  3.21100050e-01  2.00366920e-01\n",
      " -4.89313521e-01  2.94473646e-01  6.24127211e-02  1.09368973e-01\n",
      "  4.64049083e-01  4.17718663e-02 -6.40112963e-16]\n",
      "[-0.006 -0.148  0.322  0.2   -0.439  0.255  0.039  0.102  0.445  0.042\n",
      "  0.   ]\n"
     ]
    }
   ],
   "source": [
    "# Include offset / intercept\n",
    "X_new = np.pad(X,((0,0),(0,1)),mode='constant',constant_values=1)\n",
    "\n",
    "beta_bad = ols_solver(X_new,y)\n",
    "beta_good = ols_numerical(X_new,y)\n",
    "print(beta_good)\n",
    "print(beta_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (c) Calculate the mean squared error $MSE = 1/n \\sum^n_{i=1} (_i−x_iβ)^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4811605108615969"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the estimated y values for the solver and numerical OLS and use these to calculate the MSE.\n",
    "np.mean((y-X.dot(beta_good))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (d) Calculate the residual sum of squares $RSS = ∥{\\bf y} − Xβ∥_2^2$ and the total sum of squares $T SS = ∥{\\bf y} − y ̄∥_2^2$, where $y ̄$ is the estimated mean of ${\\bf y}$. Report on the $R^2$ measure, that is, the proportion of variance in the sample set explained by the\n",
    "  model: $R^2 = 1 − \\frac{RSS}{TSS}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSS = np.sum((y-X.dot(beta_good))**2)\n",
    "TSS = np.sum((y-np.mean(X.dot(beta_good)))**2)\n",
    "R2 = 1-RSS/TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5177484222203499"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
